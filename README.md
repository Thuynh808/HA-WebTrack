# HA-WEBTRACK Project

## Overview
The HA-WEBTRACK project is designed to create a high-availability web server environment using a variety of open-source tools. This infrastructure includes load balancing with HAProxy, web serving with Apache HTTPD, and comprehensive monitoring and logging with Prometheus, Grafana, Loki, and Alertmanager. The entire deployment and configuration are automated using Ansible.

## Components

Each component of the HA-WEBTRACK project plays a critical role in ensuring the high availability and robustness of the web server environment. Below is an overview of each key component used:

- **VirtualBox**: Utilized for creating and managing a secure virtual environment where all servers (Control Node, HAProxy, and Web Servers) are hosted.

- **Red Hat Enterprise Linux (RHEL) VMs**: Serve as the operating system basis for all nodes within the project, ensuring a stable and secure environment for running the web servers and load balancer.

- **Ansible**: Automation tool used for provisioning, configuring, and managing the server infrastructure to ensure consistency and repeatability across deployments.

- **HAProxy**: Acts as the load balancer, distributing incoming traffic across the two web servers to improve reliability and performance.

- **Apache HTTPD**: Web server software used on Node2 and Node3 to serve web content efficiently and reliably.

- **Prometheus**: Monitoring tool that collects and stores metrics from various components of the infrastructure.

- **Grafana**: Visualization tool that provides dashboards for real-time monitoring of the infrastructure using data collected by Prometheus.

- **Loki**: Log aggregation system integrated with Grafana to enable searching and viewing logs directly from the Grafana dashboard.

- **Alertmanager**: Manages alerts generated by Prometheus and forwards them to specified channels, such as Slack, ensuring that any potential issues are promptly addressed.

- **GitHub**: Used for version control and source code management, enabling collaborative development and historical tracking of all changes made to the project configurations and scripts.

This structured approach not only ensures that all critical components are highlighted but also provides a clear understanding of each component's role within the overall project.

## Getting Started

### Prerequisites
Before you begin, ensure you have the following prepared:
- **Four Red Hat RHEL 9 VMs**: These will act as your control node, load balancer (HAProxy), and two web servers.
- **Network Configuration**: Set IP addresses and hostnames for each VM using tools like `nmtui` to ensure proper networking. Ensure that the networking mode is set to `Bridge Adapter` to allow the VMs to directly communicate with the network as independent devices.

### Server Specifications
Below is a table outlining the specifications for each server used in the project:

| Server        | Role            | CPU | RAM  | Additional Notes                    |
|---------------|-----------------|-----|------|-------------------------------------|
| Control Node  | Management      | 2   | 4 GB | Second disk provisioned (min 20 GB) |
| Node1 (HAProxy) | Load Balancer | 2   | 4 GB |                                     |
| Node2 (WebServer) | Web Server  | 1   | 1 GB |                                     |
| Node3 (WebServer) | Web Server  | 1   | 1 GB |                                     |

> **Note:** Ensure each server meets or exceeds the specifications listed to ensure optimal performance and reliability of the HA-WEBTRACK environment.

### Setup Environment
- **Insert the RHEL ISO on control node** <br><br>
- **Run the command to mount the ISO:** <br><br>
  ```bash
  sudo mount /dev/sr0 /mnt
  ```
- **Add and configure the repository from the ISO:** <br><br>
  ```bash
  dnf config-manager --add-repo=file:///mnt/AppStream
  dnf config-manager --add-repo=file:///mnt/BaseOS
  echo "gpgcheck=0" >> /etc/yum.repos.d/mnt_AppStream.repo
  echo "gpgcheck=0" >> /etc/yum.repos.d/mnt_BaseOS.repo
  ```
- **Install `git` and `ansible-core`:** <br><br>
  ```bash
  dnf install -y git ansible-core
  ```
- **Create `ansible` user on `control node` and set password:** <br><br>
  ```bash
  useradd ansible
  passwd ansible # Follow prompts to set password
  ```
- **Add the `ansible` user to the `sudoers` file to grant necessary privileges:** <br><br>
  ```bash
  sudo echo 'ansible ALL=(ALL) NOPASSWD:ALL' > /etc/sudoers.d/ansible
  ```
- **Switch to the ansible user and set up an SSH key pair:** <br><br>
  ```bash
  su - ansible
  ssh-keygen # Press enter (3x) to accept the default file location and no passphrase
  ```

### Installation
To install and set up the project, follow these steps:

1. **Clone the repository:** <br><br>
   ```bash
   git clone https://github.com/Thuynh808/HA-WebTrack
   cd HA-WebTrack
   ```
2. **Install required Ansible collections:** <br><br>
   ```bash
   ansible-galaxy collection install -r requirements.yaml
   ```
3. **Confirm Mount the RHEL ISO:** <br><br>
   ```bash
   sudo mount /dev/sr0 /mnt
   ```
4. **Configure inventory `ansible_host`:** <br><br>
   ```bash
   vim inventory
   ```
> **Note:** Make sure to change IP addresses for all 4 servers according to your setup
5. **Run the initial setup script:** <br><br>
   ```bash
   ./initial-setup.sh
   ```
   **This script prepares our ansible environment by setting up necessary ansible user, host configurations, ssh-keys and repositories.** <br><br>
   *ansible user password: 'password'*

> **Note:** before installing components, add your slack webhook url for alertmanager to send alerts
6. **Edit alertmanager config file:** <br><br>
   ```bash
   vim roles/alertmanager/templates/alertmanager_config.j2
   ```
7. **Execute the main Ansible playbook:** <br><br>
   ```bash
   ansible-playbook site.yaml -vv
   ```
   **This command starts the configuration of all components as defined in the playbook. The -vv option increases verbosity, which can help with troubleshooting if needed.**

### Verification
After installation, verify that all components are running correctly by accessing the following URLs and ensuring that each service is operational:

### Services and URLs

  | Server | Service Name | URL |
  |--------|--------------|-----|
  | Control Node | Grafana | &lt;controlnode_ip&gt;:3000 |
  | Control Node | Prometheus | &lt;controlnode_ip&gt;:9090 |
  | Control Node | Loki(through Grafana) | &lt;controlnode_ip&gt;:3000 |
  | Control Node | Alertmanager | &lt;controlnode_ip&gt;:9093 |
  | HAProxy (node1.streetrack.org) | HAProxy | &lt;node1_ip&gt;:80 |
  | HAProxy (node1.streetrack.org) | Node Exporter | &lt;node1_ip&gt;:9100 |
  | HAProxy (node1.streetrack.org) | HAProxy Exports | &lt;node1_ip&gt;:8405/metrics |
  | HAProxy (node1.streetrack.org) | Promtail | &lt;node1_ip&gt;:9080 |
  | Web Server 1 (node2.streetrack.org) | Web Server | &lt;node2_ip&gt;:80 |
  | Web Server 1 (node2.streetrack.org) | Node Exporter | &lt;node2_ip&gt;:9100 |
  | Web Server 1 (node2.streetrack.org) | Promtail | &lt;node2_ip&gt;:9080 |
  | Web Server 2 (node3.streetrack.org) | Web Server | &lt;node3_ip&gt;:80 |
  | Web Server 2 (node3.streetrack.org) | Node Exporter | &lt;node3_ip&gt;:9100 |
  | Web Server 2 (node3.streetrack.org) | Promtail | &lt;node3_ip&gt;:9080 |


### Troubleshooting
If you encounter issues during the Ansible playbook execution, check the Ansible logs for detailed error messages.
Ensure all prerequisites are correctly installed and configured before starting the installation.
For issues related to specific components, refer to the component's documentation or the troubleshooting section of this guide.
